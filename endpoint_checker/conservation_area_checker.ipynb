{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jimmytidey/Projects/jupyter-analysis/venv/lib/python3.10/site-packages/pyproj/transformer.py:207: UserWarning: Best transformation is not available due to missing Grid(short_name=uk_os_OSTN15_NTv2_OSGBtoETRS.tif, full_name=, package_name=, url=https://cdn.proj.org/uk_os_OSTN15_NTv2_OSGBtoETRS.tif, direct_download=True, open_license=True, available=False)\n",
      "  super().__init__(\n",
      "WARNING:root:not using the best available OSGB correction tables\n"
     ]
    }
   ],
   "source": [
    "import os, time, sys,shutil\n",
    "import pandas as pd\n",
    "from digital_land.collection import Collection\n",
    "\n",
    "from functions import run_endpoint_workflow\n",
    "from sqlite_query_functions import DatasetSqlite\n",
    "from convert_functions import convert_resource\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Error 404: Not Found\n",
      "HTTP Error 404: Not Found\n",
      "data/endpoint_checker_16967532754843/collection\n",
      "[]\n",
      "*No resources collected view collection logs for more info*\n",
      "workflow_state\n",
      "No resources collected view collection logs for more info\n",
      "conditional run\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'checker_result': 'Dat checker failed - ensure you have a valid CSV, GeoJSON, GML, or Geopackage file',\n",
       " 'issues': []}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def conservation_area_checker(url):\n",
    "    collection_name = 'listed-building-collection'\n",
    "    dataset = 'listed-building-outline'\n",
    "    organisation = 'local-authority-eng:CAM'\n",
    "    endpoint_url = url\n",
    "    plugin = None\n",
    "    additional_column_mappings=None\n",
    "    additional_concats=None\n",
    "    data_dir = 'data/endpoint_checker_' + str(int(time.time()*10000)) \n",
    "\n",
    "    workflow_state = run_endpoint_workflow(\n",
    "        collection_name,\n",
    "        dataset,\n",
    "        organisation,\n",
    "        endpoint_url,\n",
    "        plugin,\n",
    "        data_dir,\n",
    "        additional_col_mappings=additional_column_mappings,\n",
    "        additional_concats=additional_concats\n",
    "    )\n",
    "    \n",
    "    print('workflow_state')\n",
    "    print(workflow_state)\n",
    "    if(workflow_state):\n",
    "        print('conditional run')\n",
    "        checker_result = 'Data checker failed - ensure you have a valid CSV, GeoJSON, GML, or Geopackage file'\n",
    "        ret = {'checker_result': checker_result, 'issues': []}\n",
    "        shutil.rmtree(data_dir)\n",
    "        return ret    \n",
    "\n",
    "\n",
    "    collection = Collection(os.path.join(data_dir,'collection'))\n",
    "    collection.load(directory=os.path.join(data_dir,'collection'))\n",
    "    logs = collection.log.entries\n",
    "    logs = pd.DataFrame.from_records(logs)\n",
    "\n",
    "    http_status = logs['status'].values[0]\n",
    "\n",
    "    if(http_status != 200): \n",
    "        checker_state = \"Could not access URL\"\n",
    "        ret = {'checker_result': checker_result, 'issues': []}\n",
    "        shutil.rmtree(data_dir)\n",
    "        return ret          \n",
    "\n",
    "    try: \n",
    "        dataset_db = DatasetSqlite(os.path.join(data_dir,'dataset',f'{dataset}.sqlite3'))\n",
    "        results = dataset_db.get_issues()\n",
    "        display(results)\n",
    "        row_count = results.shape[0]\n",
    "\n",
    "        if(row_count == 0):\n",
    "            checker_state = \"No rows were processed, check you have created a valid file.\"\n",
    "        else:\n",
    "            checker_state = f\"{row_count} rows have been processed\"\n",
    "\n",
    "        issues = results.loc[(results.issue_type != 'default-value')]\n",
    "\n",
    "    except:\n",
    "        issues = pd.DataFrame()\n",
    "\n",
    "   \n",
    "    ret = {'checker_state': checker_state, 'issues': issues.to_dict('records')}\n",
    "    \n",
    "    shutil.rmtree(data_dir)\n",
    "\n",
    "    return ret\n",
    "\n",
    "\n",
    "conservation_area_checker('https://raw.githubusercontent.com/jimmytidey/jupyter-analysis/feature-endpoint-checker-api/endpoint_checker/examples/conservation_area_invalid_csv.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
